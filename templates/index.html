<!doctype html>
<html lang="en">

<head>
    <title>Speech-To-Text Translator</title>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    <link rel="stylesheet" href="https://code.getmdl.io/1.3.0/material.indigo-pink.min.css">

    <script src="https://www.WebRTC-Experiment.com/RecordRTC.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/2.3.0/socket.io.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io-stream/0.9.1/socket.io-stream.js"></script>
</head>

<body>

    <!-- Zoom Log In -->
    <div>
        <form action="{{ url_for('login') }}" method="post">
            <!-- <input type="text" name="api" placeholder="Zoom Closed-Captioning API" style="width: 500px; height: 30px;"> -->
            <button type="submit">Zoom Login</button>
        </form>

    </div>

    <!-- Input Zoom Closed-Captioning API -->
    <div>
        <form action="{{ url_for('main') }}" method="post">
            <input type="text" name="api" placeholder="Zoom Closed-Captioning API" style="width: 500px; height: 30px;">
            <button type="submit">Submit</button>
        </form>

    </div>

    
    <!-- Get microphone input -->
    <!-- <div class="row">
        <button id="start-recording">Start Recording</button>
        <button id="stop-recording" disabled>Stop Recording</button>
    </div> -->
    
    <script type="text/javascript">

        const socketio = io();
        const socket = socketio.on('connect', function () {
            // reset the recorder
            startRecording.disabled = false;
        });

        // when the server found results send
        // it back to the client
        const resultpreview = document.getElementById('results');
        socketio.on('results', function (data) {
            // show the results on the screen
            if (data[0] && data[0].results[0] && data[0].results[0].alternatives[0]) {
                resultpreview.innerHTML += "" + data[0].results[0].alternatives[0].transcript;
            }
        });

        const startRecording = document.getElementById('start-recording');
        const stopRecording = document.getElementById('stop-recording');
        let recordAudio;

        // on start button handler
        startRecording.onclick = function () {
            // recording started
            startRecording.disabled = true;

            // make use of HTML 5/WebRTC, JavaScript getUserMedia()
            // to capture the browser microphone stream
            navigator.getUserMedia({
                audio: true
            }, function (stream) {
                recordAudio = RecordRTC(stream, {
                    type: 'audio',
                    mimeType: 'audio/webm',
                    sampleRate: 44100, // this sampleRate should be the same in your server code

                    // MediaStreamRecorder, StereoAudioRecorder, WebAssemblyRecorder
                    // CanvasRecorder, GifRecorder, WhammyRecorder
                    recorderType: StereoAudioRecorder,

                    // Dialogflow / STT requires mono audio
                    numberOfAudioChannels: 1,

                    // get intervals based blobs
                    // value in milliseconds
                    // as you might not want to make detect calls every seconds
                    timeSlice: 4000,

                    // only for audio track
                    // audioBitsPerSecond: 128000,

                    // used by StereoAudioRecorder
                    // the range 22050 to 96000.
                    // let us force 16khz recording:
                    desiredSampRate: 16000
                });

                recordAudio.startRecording();
                stopRecording.disabled = false;
            }, function (error) {
                console.error(JSON.stringify(error));
            });
        };

        // on stop button handler
        stopRecording.onclick = function () {
            // recording stopped
            startRecording.disabled = false;
            stopRecording.disabled = true;

            // stop audio recorder
            recordAudio.stopRecording(function () {

                // after stopping the audio, get the audio data
                recordAudio.getDataURL(function (audioDataURL) {
                    var files = {
                        audio: {
                            type: recordAudio.getBlob().type || 'audio/wav',
                            dataURL: audioDataURL
                        }
                    };
                    // submit the audio file to the server
                    socketio.emit('message-transcribe', files);
                });
            });
        };
    </script>


    <!-- Windows to show STT transcript -->
    <!-- <div class="row">
        <div class="col-3">
            <h3>Japanese</h3>
            <textarea id=”jap-transcript” style="width: 400px; height: 500px;"></textarea>
        </div>
        <div class="col-3">
            <h3>English</h3>
            <textarea id="eng-transcript"" style=" width: 400px; height: 500px;"></textarea>
        </div>
    </div> -->


    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
        integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"
        integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1"
        crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"
        integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM"
        crossorigin="anonymous"></script>
    <script src="../static/js/index.js"></script>
</body>

</html>